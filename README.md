# XLNetによるテキスト分類モデル

## 概要

本プロジェクトでは、事前学習済みの言語モデル **XLNet** を用いてテキスト分類モデルを構築しました。

大規模コーパスで事前学習されたモデルをファインチューニングすることで、文章の文脈情報を活用した高精度な分類を実現することを目的としています。

感情分析、カテゴリ分類、スパム検出などの自然言語処理タスクへの応用を想定しています。

---

## 使用技術

* Python
* PyTorch / TensorFlow（使用環境に応じて）
* Hugging Face Transformers
* XLNet
* NumPy / Pandas
* scikit-learn（評価指標）
* Jupyter Notebook

---

## データ前処理

### 1. テキストの整形

* 不要文字の除去
* データ形式の統一

### 2. トークナイズ

XLNetTokenizerを使用し、文章をモデル入力形式に変換。

```id="xlnet_token"
テキスト → トークンID → Attention Mask
```

### 3. データ分割

* 学習データ
* 検証データ
* テストデータ

---

## モデル構成

* モデル：XLNetForSequenceClassification
* 事前学習済みモデルを使用
* 出力：分類ラベル数に応じたSoftmax

設定：

* 損失関数：CrossEntropyLoss
* 最適化手法：AdamW

ファインチューニングにより、タスク特化型モデルとして学習。

---

## 学習と評価

* エポックごとにモデルを更新
* 検証データで性能を確認
* 評価指標：

  * Accuracy
  * Precision / Recall / F1（必要に応じて）

テストデータにより最終性能を評価。

---

## 工夫した点

* 事前学習済みXLNetを活用し、少量データでも高性能化
* トークナイズとパディング処理を適切に実装
* ファインチューニングによる効率的な学習
* 学習・検証データを分離し、過学習を防止

---

## 想定される応用

* 感情分析（ポジティブ／ネガティブ）
* ニュース・文章カテゴリ分類
* スパム検出
* FAQ分類
* カスタマーサポートの自動分類

---

## 今後の改善案

* ハイパーパラメータチューニング
* EarlyStoppingの導入
* BERTやRoBERTaとの性能比較
* データ拡張による性能向上
* Streamlitによる推論UIの実装

---

## まとめ

本プロジェクトでは、XLNetを用いたテキスト分類モデルを構築し、事前学習モデルのファインチューニングによる自然言語処理パイプラインを実装しました。
Transformerベースモデルの活用から評価までを一貫して実装し、実務応用を想定したNLPスキルを示す内容となっています。
